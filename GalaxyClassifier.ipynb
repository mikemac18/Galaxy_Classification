{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FOR THIS FILE WE ARE ATTEMPTING TO TRAIN OUR MODEL AFTER GETTING OUR FEATURES\n",
    "Implementing method outlined in this paper:\n",
    "https://www-cs.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from cv2 import cv2 #Use 'pip install opencv-python' to get module if you don't have it\n",
    "import glob\n",
    "import os\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class GetImage(object):\n",
    "    #Load raw image files\n",
    "    \n",
    "    #initialize the path (TODO - make basepath an input parameter, don't hardcode too much)\n",
    "\n",
    "    #Data should be stored in Users/YOUR_USER_NAME/321_galaxies/images_training_rev1\n",
    "    def __init__(self, num_pics=15000, username='mike'):\n",
    "        self.num_pics = num_pics\n",
    "        self.basepath = '/Users/'+username+'/321_galaxies/'\n",
    "        self.imPath_test = 'images_test_rev1/'\n",
    "        self.imPath_training =  'images_training_rev1/'\n",
    "        self.solPath = 'training_solutions_rev1.csv'\n",
    "        self.solutions=np.loadtxt(self.basepath + self.solPath, delimiter=',', skiprows=1)[:num_pics, 1:4]\n",
    "        self.patchvector = []\n",
    "       \n",
    "        #create variable that stores the image\n",
    "        self.images = []\n",
    "        i=0\n",
    "        for filename in glob.glob(self.basepath + self.imPath_training+'*.jpg'): #assuming jpg\n",
    "            if(i >= num_pics):\n",
    "                break\n",
    "            im=cv2.imread(filename)\n",
    "            self.images.append(im)\n",
    "            i +=1 \n",
    "        self.cropped_images = []\n",
    "        self.scaled_images = []\n",
    "        self.patches = []\n",
    "       \n",
    "    #Get category labels for each image from the solutions file\n",
    "    def getLabels(self):\n",
    "        self.label=[]\n",
    "        for i in self.solutions:\n",
    "            self.m = np.where(i == max(i))[0][0]\n",
    "            self.label.append(self.m)\n",
    "        self.label=np.array(self.label)\n",
    "        return self\n",
    "    \n",
    "    #Crop image from 424x424 to 160x160. To do we crop axes from {x=0, y=0, x=424, y=424 } => {x=132, y=132, x=292, 400=292}\n",
    "    def crop(self, pixels_to_keep = 160):\n",
    "        for galaxyPic in self.images:\n",
    "            #Cast as int in order to use variables in the slicing indices\n",
    "            center = int(424/2)\n",
    "            dim = int(pixels_to_keep/2)\n",
    "            cropmin = center - dim\n",
    "            cropmax = center + dim\n",
    "            self.cropped_images.append(galaxyPic[cropmin:cropmax, cropmin:cropmax])\n",
    "        return self\n",
    "\n",
    "    #function that takes an image and scales the entire image to its new size (unlike crop, image stays intact). \n",
    "    def scale(self, new_size = 16):\n",
    "        for galaxyPic in self.cropped_images:\n",
    "            dimensions = (int(new_size), int(new_size))\n",
    "            self.scaled_images.append(cv2.resize(galaxyPic, dimensions))\n",
    "        return self\n",
    "    \n",
    "    #function that crops out the four 8x8 patches that compose each image.\n",
    "    def patch(self, p_size=8):\n",
    "        for galaxyPic in self.scaled_images:\n",
    "            #Gets the center for each of the four patches\n",
    "            for i in (4, 12):\n",
    "                for j in (4, 12):\n",
    "                    patch_x = i\n",
    "                    patch_y = j\n",
    "                    dim = int(p_size/2)\n",
    "                    patchminx = patch_x - dim\n",
    "                    patchminy = patch_y - dim\n",
    "                    patchmaxx = patch_x + dim\n",
    "                    patchmaxy = patch_y + dim\n",
    "                    self.patches.append(galaxyPic[patchminx:patchmaxx, patchminy:patchmaxy])\n",
    "        return self\n",
    "    #function that sums the values for the different filters and\n",
    "    #flatten the 4x4 matrixes for each patch to a 1x16 vector\n",
    "    def makevector(self):\n",
    "        self.newpatches = np.sum(self.patches, axis = 3)\n",
    "        \n",
    "        for i in self.newpatches:\n",
    "            self.patchvector.append(np.matrix.flatten(i).tolist())\n",
    "        self.patchvector=np.array(self.patchvector)\n",
    "        return self\n",
    "    \n",
    "        \n",
    "    ## Function that normalizes the pixel values. Takes vstack of patches as input\n",
    "    def normalize(self):\n",
    "        temp1 = self.patchvector - self.patchvector.mean(1, keepdims=True)\n",
    "        temp2 = np.sqrt(self.patchvector.var(1, keepdims=True) + 10)\n",
    "        self.patchvector = temp1/temp2\n",
    "        return self\n",
    "    ## Function to perform ZCA whitening to decorrelate our pixels\n",
    "    def whiten(self):\n",
    "        cov = np.cov(self.patchvector, rowvar=0)\n",
    "        self.mean = self.patchvector.mean(0, keepdims=True)\n",
    "        d, v = np.linalg.eig(cov)\n",
    "        self.p = np.dot(v, np.dot(np.diag(np.sqrt(1 / (d + 0.1))), v.T))\n",
    "        self.patchvector = np.dot(self.patchvector - self.mean, self.p)\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class extractFeatures():\n",
    "\n",
    "    def __init__(self, vectorPatches, k = 100):\n",
    "        #Making a dictionnary of centroids from our patch vectors\n",
    "        self.k = k\n",
    "        self.patches = vectorPatches\n",
    "        self.dictionary = self.Kmeans()\n",
    "        #We then use this dictionnary to create features for each patch vector\n",
    "        self.features = []\n",
    "        for patch in self.patches:\n",
    "            self.features.append(np.matmul(self.dictionary, patch))\n",
    "        self.features = np.array(self.features)\n",
    "\n",
    "    def getActualFeatures(self):\n",
    "        self.truefeatures=[]\n",
    "        for i in range(int(len(self.features) / 4)) :\n",
    "            self.truefeatures.append((self.features[4*i], self.features[4*i+1], self.features[4*i+2], self.features[4*i+3]))\n",
    "        self.truefeatures = np.array(self.truefeatures)\n",
    "        return self.truefeatures\n",
    "\n",
    "    def Kmeans(self, iters = 25, batch_size = 1000):\n",
    "        L2 = np.sum(self.patches**2, 1, keepdims=True)\n",
    "        #initialize centroids\n",
    "        self.centroids = np.random.randn(self.k, self.patches.shape[1]) * 0.1\n",
    "        for iteration in range(1, iters+1):\n",
    "            c2 = np.sum(self.centroids**2, 1, keepdims=True)\n",
    "            summation = np.zeros((self.k, self.patches.shape[1]))\n",
    "            counts = np.zeros((self.k, 1))\n",
    "            loss = 0\n",
    "            for i in range(0, self.patches.shape[0], batch_size):\n",
    "                last_index = min(i + batch_size, self.patches.shape[0])\n",
    "                m = last_index - i\n",
    "\n",
    "                # shape (k, batch_size) - shape (k, 1)\n",
    "                tmp = np.dot(self.centroids, self.patches[i:last_index, :].T) - c2\n",
    "                # shape (batch_size, )\n",
    "                indices = np.argmax(tmp, 0)\n",
    "                # shape (1, batch_size)\n",
    "                val = np.max(tmp, 0, keepdims=True)\n",
    "\n",
    "                loss += np.sum((0.5 * L2[i:last_index]) - val.T)\n",
    "\n",
    "                # Don't use a sparse matrix here\n",
    "                S = np.zeros((batch_size, self.k))\n",
    "                S[range(batch_size), indices] = 1\n",
    "\n",
    "                # shape (k, n_pixels)\n",
    "                this_sum = np.dot(S.T, self.patches[i:last_index, :])\n",
    "                summation += this_sum\n",
    "\n",
    "                this_counts = np.sum(S, 0, keepdims=True).T\n",
    "                counts += this_counts \n",
    "            \n",
    "            self.centroids = summation / counts\n",
    "        \n",
    "            bad_indices = np.where(counts == 0)[0]\n",
    "            self.centroids[bad_indices, :] = 0\n",
    "        return self.centroids\n",
    "\n",
    "\n",
    "class classifyGalaxies():\n",
    "\n",
    "    def __init__(self, galaxyPics, featureExtractor, percentForTrain = 0.75):\n",
    "\n",
    "        self.galaxyPics = galaxyPics\n",
    "        self.num_pics = galaxyPics.num_pics\n",
    "        self.truefeatures = featureExtractor.getActualFeatures()\n",
    "        ##Reshaping our features for our multiclass algorithm in the next cell\n",
    "        self.nsamples, self.nx, self.ny = self.truefeatures.shape\n",
    "        self.truefeatures = self.truefeatures.reshape((self.nsamples,self.nx*self.ny))\n",
    "        self.partition = int(percentForTrain*self.num_pics)\n",
    "        ###Separating the training data and test data for our multiclass model\n",
    "        self.train_x = self.truefeatures[:self.partition]\n",
    "        self.train_y = galaxyPics.label[:self.partition]\n",
    "        self.test_x = self.truefeatures[self.partition:self.num_pics]\n",
    "        self.test_y = galaxyPics.label[self.partition:self.num_pics]\n",
    "\n",
    "    ### Function that tests the accuracy using the Root Mean Squared Method\n",
    "###Here we use the probabilities that an image belongs in a cluster to get a better\n",
    "###value of accuracy\n",
    "    def testRMS(self, preds, labels):\n",
    "        count = 0\n",
    "        N = len(preds) * 3\n",
    "        for i in range(len(preds)):\n",
    "            for j in range(len(preds[0])):\n",
    "                count += (preds[i][j] - labels[i][j])**2\n",
    "        return 100*(1-np.sqrt(count/N))\n",
    "    \n",
    "\n",
    "    def classify(self, useSVC = True, useGradientBoosting = True, useRadiusNeighbors = True, useRandomForest = True, useLogisticRegression = True):\n",
    "        if(useSVC):\n",
    "            model=OneVsRestClassifier(SVC(random_state=0, max_iter=50000, probability=True)).fit(self.train_x, self.train_y)\n",
    "            predictions = model.predict(self.test_x)\n",
    "            predictproba = model.predict_proba(self.test_x)\n",
    "            print(\"The root mean square accuracy using SVC is: \" )\n",
    "            print(self.testRMS(predictproba, self.galaxyPics.solutions[self.partition:self.num_pics]))\n",
    "\n",
    "        if(useGradientBoosting):\n",
    "            model = GradientBoostingClassifier(n_estimators=300, learning_rate=0.001, max_depth=3, random_state=0).fit(self.train_x, self.train_y)\n",
    "            pred = model.predict_proba(self.test_x)\n",
    "            print(\"\\n The root mean square accuracy using Gradient Boosting is: \") \n",
    "            print(self.testRMS(pred, self.galaxyPics.solutions[self.partition:self.num_pics]))\n",
    "\n",
    "        if(useRadiusNeighbors):\n",
    "            neigh = RadiusNeighborsClassifier(radius=2000.0)\n",
    "            neigh.fit(self.train_x, self.train_y)\n",
    "            pred = neigh.predict_proba(self.test_x)\n",
    "            print(\"\\n The root mean square accuracy using Radius Neighbors is: \")\n",
    "            print(self.testRMS(pred, self.galaxyPics.solutions[self.partition:self.num_pics]))\n",
    "\n",
    "        if(useRandomForest):\n",
    "            clf2 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "            clf2.fit(self.train_x, self.train_y)\n",
    "            pred4 = clf2.predict_proba(self.test_x)\n",
    "            print(\"\\n The root mean square accuracy using Random Forest is: \") \n",
    "            print(self.testRMS(pred4, self.galaxyPics.solutions[self.partition:self.num_pics]))\n",
    "\n",
    "        if(useLogisticRegression):\n",
    "            model4 = LogisticRegression(random_state=0, max_iter=50000).fit(self.train_x, self.train_y)\n",
    "            predict2 = model4.predict_proba(self.test_x)\n",
    "            print(\"\\n The root mean square accuracy using Logistic Regression is: \" )\n",
    "            print(self.testRMS(predict2, self.galaxyPics.solutions[self.partition:self.num_pics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-bc309c43aece>:169: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.centroids = summation / counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root mean square accuracy using SVC is: \n",
      "76.28223624710746\n",
      "\n",
      " The root mean square accuracy using Gradient Boosting is: \n",
      "76.29742525808594\n",
      "\n",
      " The root mean square accuracy using Radius Neighbors is: \n",
      "76.27531827825024\n",
      "\n",
      " The root mean square accuracy using Random Forest is: \n",
      "76.28130197271764\n",
      "\n",
      " The root mean square accuracy using Logistic Regression is: \n",
      "76.15047551673597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Testing the class by creating a 'galaxyPic' object, cropping it, scaling it, extracting patches, making the \n",
    "#patch vectors, normalizing and whitening the pixel values. \n",
    "galaxyPics = GetImage()\n",
    "galaxyPics.getLabels()\n",
    "galaxyPics.crop()\n",
    "galaxyPics.scale()\n",
    "galaxyPics.patch()\n",
    "galaxyPics.makevector()\n",
    "galaxyPics.normalize()\n",
    "galaxyPics.whiten()\n",
    "\n",
    "featureClass = extractFeatures(galaxyPics.patchvector)\n",
    "\n",
    "features = featureClass.getActualFeatures()\n",
    "\n",
    "classifier = classifyGalaxies(galaxyPics, featureClass)\n",
    "\n",
    "classifier.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running again with 200 centroids\n",
    "galaxyPics = GetImage()\n",
    "galaxyPics.getLabels()\n",
    "galaxyPics.crop()\n",
    "galaxyPics.scale()\n",
    "galaxyPics.patch()\n",
    "galaxyPics.makevector()\n",
    "galaxyPics.normalize()\n",
    "galaxyPics.whiten()\n",
    "\n",
    "featureClass = extractFeatures(galaxyPics.patchvector, k=200)\n",
    "\n",
    "features = featureClass.getActualFeatures()\n",
    "\n",
    "classifier = classifyGalaxies(galaxyPics, featureClass)\n",
    "\n",
    "classifier.classify()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
